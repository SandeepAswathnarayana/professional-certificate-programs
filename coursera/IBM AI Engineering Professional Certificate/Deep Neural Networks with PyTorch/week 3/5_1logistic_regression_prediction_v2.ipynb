{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "5.1logistic_regression_prediction_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY7zU7K6vleq",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"http://cocl.us/pytorch_link_top\">\n",
        "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
        "</a> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVuDbDz7vler",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz_gH3uwvles",
        "colab_type": "text"
      },
      "source": [
        "<h1>Logistic Regression</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nwv0Zh1vlet",
        "colab_type": "text"
      },
      "source": [
        "<h2>Table of Contents</h2>\n",
        "<p>In this lab, we will cover logistic regression using PyTorch.</p>\n",
        "\n",
        "<ul>\n",
        "    <li><a href=\"#Log\">Logistic Function</a></li>\n",
        "    <li><a href=\"#Seq\">Build a Logistic Regression Using nn.Sequential</a></li>\n",
        "    <li><a href=\"#Model\">Build Custom Modules</a></li>\n",
        "</ul>\n",
        "<p>Estimated Time Needed: <strong>15 min</strong></p>\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvb9bveVvleu",
        "colab_type": "text"
      },
      "source": [
        "<h2>Preparation</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rfTIX06vlev",
        "colab_type": "text"
      },
      "source": [
        "We'll need the following libraries:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHwzVkx8vlev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the libraries we need for this lab\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVwdCgubvle0",
        "colab_type": "text"
      },
      "source": [
        "Set the random seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBNnR35nvle1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7920962a-1fd8-40e7-fc99-5285de68dfde"
      },
      "source": [
        "# Set the random seed\n",
        "\n",
        "torch.manual_seed(2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4ae285d2f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUkeR7nvvle7",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naTuk3tUvle7",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Log\">Logistic Function</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2TuoPUSvle8",
        "colab_type": "text"
      },
      "source": [
        "Create a tensor ranging from -100 to 100:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMI3DmaAvle9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c3137ca1-36b3-4361-eb46-e820dddf85b2"
      },
      "source": [
        "z = torch.arange(-100, 100, 0.1).view(-1, 1)\n",
        "print(\"The tensor: \", z)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensor:  tensor([[-100.0000],\n",
            "        [ -99.9000],\n",
            "        [ -99.8000],\n",
            "        ...,\n",
            "        [  99.7000],\n",
            "        [  99.8000],\n",
            "        [  99.9000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRr9b9javlfA",
        "colab_type": "text"
      },
      "source": [
        "Create a sigmoid object: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV00rIzQvlfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create sigmoid object\n",
        "\n",
        "sig = nn.Sigmoid()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILhTLaH5vlfF",
        "colab_type": "text"
      },
      "source": [
        "Apply the element-wise function Sigmoid with the object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w11BzO4zvlfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use sigmoid object to calculate the \n",
        "\n",
        "yhat = sig(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNGQCUiKvlfP",
        "colab_type": "text"
      },
      "source": [
        "Plot the results: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3delq8GvlfQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "99df5503-3580-4b9f-8320-a8d0a9743710"
      },
      "source": [
        "plt.plot(z.numpy(), yhat.numpy())\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('yhat')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'yhat')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8VLc_tovlfZ",
        "colab_type": "text"
      },
      "source": [
        "Apply the element-wise Sigmoid from the function module and plot the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwRmkGtbvlfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f948daf1-3bd3-424f-d328-4893861946b8"
      },
      "source": [
        "yhat = torch.sigmoid(z)\n",
        "plt.plot(z.numpy(), yhat.numpy())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4ae1e83710>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YptGKzo3vlfe",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXU-sZn9vlfg",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Seq\">Build a Logistic Regression with <code>nn.Sequential</code></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS4oJP3pvlfh",
        "colab_type": "text"
      },
      "source": [
        "Create a 1x1 tensor where x represents one data sample with one dimension, and 2x1 tensor X represents two data samples of one dimension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ37p0ctvlfi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ed2ea331-25f2-4e47-e9ac-e680b5cfbde9"
      },
      "source": [
        "# Create x and X tensor\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "X = torch.tensor([[1.0], [100]])\n",
        "print('x = ', x)\n",
        "print('X = ', X)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  tensor([[1.]])\n",
            "X =  tensor([[  1.],\n",
            "        [100.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sw23Tgrvlfs",
        "colab_type": "text"
      },
      "source": [
        "Create a logistic regression object with the <code>nn.Sequential</code> model with a one-dimensional input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed9FO9Rivlft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use sequential function to create model\n",
        "\n",
        "model = nn.Sequential(nn.Linear(1, 1), nn.Sigmoid())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N-VYh09vlfw",
        "colab_type": "text"
      },
      "source": [
        "The object is represented in the following diagram: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hzpy9h1vlfx",
        "colab_type": "text"
      },
      "source": [
        "<img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.1.1_logistic_regression_block_diagram.png\" width = 800, align = \"center\" alt=\"logistic regression block diagram\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGUysLYEvlfx",
        "colab_type": "text"
      },
      "source": [
        "In this case, the parameters are randomly initialized. You can view them the following ways:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-cILO8wvlfy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "8731e23f-503e-4166-e34e-99377dd1977d"
      },
      "source": [
        "# Print the parameters\n",
        "\n",
        "print(\"list(model.parameters()):\\n \", list(model.parameters()))\n",
        "print(\"\\nmodel.state_dict():\\n \", model.state_dict())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "list(model.parameters()):\n",
            "  [Parameter containing:\n",
            "tensor([[0.2294]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.2380], requires_grad=True)]\n",
            "\n",
            "model.state_dict():\n",
            "  OrderedDict([('0.weight', tensor([[0.2294]])), ('0.bias', tensor([-0.2380]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEqulCSyvlf1",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with one sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd43r0qKvlf2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bbe09c24-8c24-4b5a-af3d-82b4e7434034"
      },
      "source": [
        "# The prediction for x\n",
        "\n",
        "yhat = model(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.4979]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twhqqpOivlf6",
        "colab_type": "text"
      },
      "source": [
        "Calling the object with tensor <code>X</code> performed the following operation <b>(code values may not be the same as the diagrams value  depending on the version of PyTorch) </b>:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-qwuXiivlf7",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.1.1_logistic_functio_example%20.png\" width=\"400\" alt=\"Logistic Example\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DHNUm5Uvlf8",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with multiple samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnj18FR4vlf-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0d0cc3e3-35c2-45a8-af26-64dfdbc68909"
      },
      "source": [
        "# The prediction for X\n",
        "\n",
        "yhat = model(X)\n",
        "yhat"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4979],\n",
              "        [1.0000]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG9KkMqlvlgC",
        "colab_type": "text"
      },
      "source": [
        "Calling the object performed the following operation: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmKxaL-nvlgD",
        "colab_type": "text"
      },
      "source": [
        "Create a 1x2 tensor where x represents one data sample with one dimension, and 2x3 tensor X represents one data sample of two dimensions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YPghGE0vlgF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "36cf5c64-92bf-40c1-bc84-f49441a69ddd"
      },
      "source": [
        "# Create and print samples\n",
        "\n",
        "x = torch.tensor([[1.0, 1.0]])\n",
        "X = torch.tensor([[1.0, 1.0], [1.0, 2.0], [1.0, 3.0]])\n",
        "print('x = ', x)\n",
        "print('X = ', X)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  tensor([[1., 1.]])\n",
            "X =  tensor([[1., 1.],\n",
            "        [1., 2.],\n",
            "        [1., 3.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1mgn4vkvlgJ",
        "colab_type": "text"
      },
      "source": [
        "Create a logistic regression object with the <code>nn.Sequential</code> model with a two-dimensional input: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZy4q1nfvlgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create new model using nn.sequential()\n",
        "\n",
        "model = nn.Sequential(nn.Linear(2, 1), nn.Sigmoid())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pjYjxIrvlgP",
        "colab_type": "text"
      },
      "source": [
        "The object will apply the Sigmoid function to the output of the linear function as shown in the following diagram:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6HtDsFOvlgQ",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.1.1logistic_output.png\" width=\"800\" alt=\"The structure of nn.sequential\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaUXTPPuvlgR",
        "colab_type": "text"
      },
      "source": [
        "In this case, the parameters are randomly initialized. You can view them the following ways:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shizP0N-vlgS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d4fb1ae3-6402-4d3d-927d-6204957247a2"
      },
      "source": [
        "# Print the parameters\n",
        "\n",
        "print(\"list(model.parameters()):\\n \", list(model.parameters()))\n",
        "print(\"\\nmodel.state_dict():\\n \", model.state_dict())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "list(model.parameters()):\n",
            "  [Parameter containing:\n",
            "tensor([[ 0.1939, -0.0361]], requires_grad=True), Parameter containing:\n",
            "tensor([0.3021], requires_grad=True)]\n",
            "\n",
            "model.state_dict():\n",
            "  OrderedDict([('0.weight', tensor([[ 0.1939, -0.0361]])), ('0.bias', tensor([0.3021]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ1aMVJzvlgV",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with one sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DALBxlLTvlgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "82c7215e-3001-4806-c176-0be57f2535aa"
      },
      "source": [
        "# Make the prediction of x\n",
        "\n",
        "yhat = model(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.6130]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhaygAKYvlgc",
        "colab_type": "text"
      },
      "source": [
        "The operation is represented in the following diagram:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXwD7Vn-vlgg",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.3.1.logisticwithouptut.png\" width=\"500\" alt=\"Sequential Example\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "214gcdFSvlgh",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with multiple samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwVw7c_ivlgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b34a90f3-648e-4389-ea13-32afe9835834"
      },
      "source": [
        "# The prediction of X\n",
        "\n",
        "yhat = model(X)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.6130],\n",
            "        [0.6044],\n",
            "        [0.5957]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCUaZwlvvlgp",
        "colab_type": "text"
      },
      "source": [
        "The operation is represented in the following diagram: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzGOjbYYvlgq",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.1.1_logistic_with_outputs2.png\" width=\"800\" alt=\"Sequential Example\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5pOE3D_vlgu",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCuPNN3lvlgv",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Model\">Build Custom Modules</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6wzzpj_vlgx",
        "colab_type": "text"
      },
      "source": [
        "In this section, you will build a custom Module or class. The model or object function is identical to using <code>nn.Sequential</code>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7LW1iv7vlg2",
        "colab_type": "text"
      },
      "source": [
        "Create a logistic regression custom module:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L5UaEmjvlg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logistic_regression custom class\n",
        "\n",
        "class logistic_regression(nn.Module):\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self, n_inputs):\n",
        "        super(logistic_regression, self).__init__()\n",
        "        self.linear = nn.Linear(n_inputs, 1)\n",
        "    \n",
        "    # Prediction\n",
        "    def forward(self, x):\n",
        "        yhat = torch.sigmoid(self.linear(x))\n",
        "        return yhat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9YaCz4Yvlg9",
        "colab_type": "text"
      },
      "source": [
        "Create a 1x1 tensor where x represents one data sample with one dimension, and 3x1 tensor where $X$ represents one data sample of one dimension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE8Sqgl4vlg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "de7e0ce7-242e-4f49-dcfb-c56b3f7936da"
      },
      "source": [
        "# Create x and X tensor\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "X = torch.tensor([[-100], [0], [100.0]])\n",
        "print('x = ', x)\n",
        "print('X = ', X)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  tensor([[1.]])\n",
            "X =  tensor([[-100.],\n",
            "        [   0.],\n",
            "        [ 100.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkFb33QAvlhE",
        "colab_type": "text"
      },
      "source": [
        "Create a model to predict one dimension: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9qkefN-vlhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logistic regression model\n",
        "\n",
        "model = logistic_regression(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnmeXdaLvlhL",
        "colab_type": "text"
      },
      "source": [
        "In this case, the parameters are randomly initialized. You can view them the following ways:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIOOgdqsvlhL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "07ecaeb5-8da1-4230-ed7b-7313ffb69357"
      },
      "source": [
        "# Print parameters \n",
        "\n",
        "print(\"list(model.parameters()):\\n \", list(model.parameters()))\n",
        "print(\"\\nmodel.state_dict():\\n \", model.state_dict())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "list(model.parameters()):\n",
            "  [Parameter containing:\n",
            "tensor([[0.2381]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.1149], requires_grad=True)]\n",
            "\n",
            "model.state_dict():\n",
            "  OrderedDict([('linear.weight', tensor([[0.2381]])), ('linear.bias', tensor([-0.1149]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSCzhExSvlhQ",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with one sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiihLJ6yvlhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make the prediction of x\n",
        "\n",
        "yhat = model(x)\n",
        "print(\"The prediction result: \\n\", yhat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf-Bo3EVvlhU",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with multiple samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEpGkaCnvlhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1473a0dc-6033-486c-93dd-503ecac713bf"
      },
      "source": [
        "# Make the prediction of X\n",
        "\n",
        "yhat = model(X)\n",
        "print(\"The prediction result: \\n\", yhat)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction result: \n",
            " tensor([[4.0805e-11],\n",
            "        [4.7130e-01],\n",
            "        [1.0000e+00]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjVsiLAkvlhi",
        "colab_type": "text"
      },
      "source": [
        "Create a logistic regression object with a function with two inputs: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W98hFvWXvlhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logistic regression model\n",
        "\n",
        "model = logistic_regression(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNyF4KNAvlhl",
        "colab_type": "text"
      },
      "source": [
        "Create a 1x2 tensor where x represents one data sample with one dimension, and 3x2 tensor X represents one data sample of one dimension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbNsjQaWvlhm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "93b39dc0-c392-4e48-a4e7-99823bdcfd7b"
      },
      "source": [
        "# Create x and X tensor\n",
        "\n",
        "x = torch.tensor([[1.0, 2.0]])\n",
        "X = torch.tensor([[100, -100], [0.0, 0.0], [-100, 100]])\n",
        "print('x = ', x)\n",
        "print('X = ', X)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  tensor([[1., 2.]])\n",
            "X =  tensor([[ 100., -100.],\n",
            "        [   0.,    0.],\n",
            "        [-100.,  100.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD-iux4kvlhp",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with one sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn8VHN6Cvlhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "297e4fbe-ba76-4681-c7f5-e649e366adfd"
      },
      "source": [
        "# Make the prediction of x\n",
        "\n",
        "yhat = model(x)\n",
        "print(\"The prediction result: \\n\", yhat)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction result: \n",
            " tensor([[0.2943]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9NWkfpuvlhs",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with multiple samples: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsmxAmHWvlhs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "447fee1f-cc80-4ca2-c343-50b8aba60774"
      },
      "source": [
        "# Make the prediction of X\n",
        "\n",
        "yhat = model(X)\n",
        "print(\"The prediction result: \\n\", yhat)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction result: \n",
            " tensor([[7.7529e-33],\n",
            "        [3.4841e-01],\n",
            "        [1.0000e+00]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByZFsdcMvlhx",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXLupPpzvlhx",
        "colab_type": "text"
      },
      "source": [
        "<h3>Practice</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqaJukEwvlhy",
        "colab_type": "text"
      },
      "source": [
        "Make your own model <code>my_model</code> as applying linear regression first and then logistic regression using <code>nn.Sequential()</code>. Print out your prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcgxmR17vlhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "517bdce8-8582-4425-d54d-04dbf0affa2e"
      },
      "source": [
        "# Practice: Make your model and make the prediction\n",
        "\n",
        "X = torch.tensor([-10.0])\n",
        "\n",
        "my_model = nn.Sequential(nn.Linear(1, 1),nn.Sigmoid())\n",
        "yhat = my_model(X)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([0.2231], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHQpNt9svlh2",
        "colab_type": "text"
      },
      "source": [
        "Double-click <b>here</b> for the solution.\n",
        "\n",
        "<!-- \n",
        "my_model = nn.Sequential(nn.Linear(1, 1),nn.Sigmoid())\n",
        "yhat = my_model(X)\n",
        "print(\"The prediction: \", yhat)\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJj_4zhYvlh3",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6QDtT6Gvlh4",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"http://cocl.us/pytorch_link_bottom\">\n",
        "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/notebook_bottom%20.png\" width=\"750\" alt=\"PyTorch Bottom\" />\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDbBBTwzvlh4",
        "colab_type": "text"
      },
      "source": [
        "<h2>About the Authors:</h2> \n",
        "\n",
        "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_WiQ5ZHvlh5",
        "colab_type": "text"
      },
      "source": [
        "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1-IjtT4vlh5",
        "colab_type": "text"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvl9XwvAvlh6",
        "colab_type": "text"
      },
      "source": [
        "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
      ]
    }
  ]
}